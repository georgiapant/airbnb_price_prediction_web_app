{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h58u3Y8WnGaw",
        "outputId": "bf818089-3925-4a28-a27f-7ea0e8cf3f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bo2x3HsynP-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac56e5b1-ae94-4422-9bd2-255e7d172974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpyencoder\n",
            "  Downloading numpyencoder-0.3.0-py3-none-any.whl (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from numpyencoder) (1.21.6)\n",
            "Installing collected packages: numpyencoder\n",
            "Successfully installed numpyencoder-0.3.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from numpy import inf\n",
        "from geopy.distance import vincenty\n",
        "import json\n",
        "!pip install numpyencoder\n",
        "from numpyencoder import NumpyEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h0osOkAUnUVE"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/project/data/' "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data"
      ],
      "metadata": {
        "id": "CYeGa-JDXcEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers(df,cols, q1, q3):\n",
        "    '''\n",
        "    Function that removes the outliers of a set\n",
        "    \n",
        "    Inputs:\n",
        "    - df: dataframe of the data\n",
        "    - cols: The coloumns for wich the outliers need to be removed\n",
        "    - q1: below whitc quantile to drop\n",
        "    - q3: above which quantile to keep\n",
        "    \n",
        "    Output:\n",
        "    The dataframe without the outliers\n",
        "    '''\n",
        "    \n",
        "    Q1 = df[cols].quantile(q1)\n",
        "    Q3 = df[cols].quantile(q3)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    df = df[~((df[cols] < (Q1 - 1.5 * IQR)) |(df[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "    return df"
      ],
      "metadata": {
        "id": "Yfa-Bb-gXa6r"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_neigh_groupings(df):\n",
        "    '''\n",
        "    A function that creates the neighbourhood groupings based on the neighbourhood prices\n",
        "    \n",
        "    Input:\n",
        "    df: The dataframe with the data. Needs to have a column named 'neighbourhood_clensed' and one named 'price'\n",
        "    \n",
        "    Output:\n",
        "    A dictionary with keys all the neighbourhoods and value the group they belong\n",
        "    '''\n",
        "    groups_neigh = df.groupby('neighbourhood_cleansed').agg(np.mean)['price']\n",
        "    groups_neigh = groups_neigh.sort_values()\n",
        "\n",
        "    groups_neigh.values\n",
        "    groups_neigh_1 = groups_neigh[:6]\n",
        "    groups_neigh_2 = groups_neigh[6:12]\n",
        "    groups_neigh_3 = groups_neigh[12:18]\n",
        "    groups_neigh_4 = groups_neigh[18:24]\n",
        "    groups_neigh_5 = groups_neigh[24:30]\n",
        "    groups_neigh_6 = groups_neigh[30:37]\n",
        "    groups_neigh_7 = groups_neigh[37:44]\n",
        "\n",
        "    d1 = dict.fromkeys(groups_neigh_1.index, '1')\n",
        "    d2 = dict.fromkeys(groups_neigh_2.index, '2')\n",
        "    d3 = dict.fromkeys(groups_neigh_3.index, '3')\n",
        "    d4 = dict.fromkeys(groups_neigh_4.index, '4')\n",
        "    d5 = dict.fromkeys(groups_neigh_5.index, '5')\n",
        "    d6 = dict.fromkeys(groups_neigh_6.index, '6')\n",
        "    d7 = dict.fromkeys(groups_neigh_7.index, '7')\n",
        "\n",
        "    neigh_group = {**d1, **d2, **d3, **d4, **d5, **d6, **d7}\n",
        "    return neigh_group\n"
      ],
      "metadata": {
        "id": "0kiFMWtJXa97"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def missing_values_n_encoding(df, neigh_group):\n",
        "    '''\n",
        "    Function that fills missing values, encodes features and creates new features\n",
        "\n",
        "    Inputs:\n",
        "    - the dataframe and the neighbourhood grouping\n",
        "    \n",
        "    Outputs:\n",
        "    The new dataframe without any missing valuees, encoded features and new features\n",
        "    '''\n",
        "    # Host feature handling\n",
        "    df['host_is_superhost'] = df['host_is_superhost'].map({'t':1, 'f':0})\n",
        "    df[['host_about', 'license']] = df[['host_about', 'license']].applymap(lambda x: 0 if pd.isnull(x) else 1)\n",
        "    df['host_verifications'] = df['host_verifications'].apply(lambda row: len(row))\n",
        "    df = df[~df['host_is_superhost'].isnull()]\n",
        "    df['host_response_rate'] = df['host_response_rate'].str[:-1].astype('float64')\n",
        "    df['host_response_rate'] = pd.cut(df['host_response_rate'], \n",
        "                                bins=[0, 50, 90, 99, 100], \n",
        "                                labels=['0-49%', '50-89%', '90-99%', '100%'], \n",
        "                                include_lowest=True)\n",
        "\n",
        "    df['host_response_rate'] = df['host_response_rate'].astype('str')\n",
        "    df['host_response_rate'] = df['host_response_rate'].replace('nan', 'unknown')\n",
        "    df['host_response_time']= df['host_response_time'].fillna(\"unknown\")\n",
        "\n",
        "\n",
        "    # Listing features handling\n",
        "    df['instant_bookable'] = df['instant_bookable'].map({'t':1, 'f':0})\n",
        "    df['has_availability'] = df['has_availability'].map({'t':1, 'f':0})\n",
        "    df['shared_bath'] = df['bathrooms_text'].apply(lambda s: 1 if 'shared' in str(s).split(' ') else 0) \n",
        "    df['bathrooms'] = df['bathrooms_text'].apply(lambda s: float(0.5) if 'half-bath' in str(s).lower() else float(str(s).split(' ')[0]))\n",
        "    df['bathrooms'] = df['bathrooms'].fillna(0)\n",
        "\n",
        "\n",
        "    # New features creation\n",
        "    df['lat_center'] = 37.9715\n",
        "    df['lon_center'] = 23.7257\n",
        "\n",
        "    df['distance_parthenon'] = df.apply(lambda x: vincenty((x['latitude'], x['longitude']), (x['lat_center'], x['lon_center'])).km, axis = 1)\n",
        "    df['amenities_number'] = df['amenities'].apply(lambda s: len(str(s)[1:].split(',')))\n",
        "    df['neighbourhood_cleansed_group'] = df['neighbourhood_cleansed'].map(neigh_group)\n",
        "\n",
        "    df = df.drop(columns=['lat_center','lon_center'])\n",
        "    df = df.drop(columns=['bathrooms_text', 'amenities'])\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "gW0Ulsj4XbAn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers_per_room_type(df):\n",
        "    '''\n",
        "    Function that removes the outliers for the columns 'price', 'maximum_nights', 'minimum_nights' for each room type seperatetly\n",
        "\n",
        "    Input:\n",
        "    - Data frame to be processed\n",
        "\n",
        "    Output:\n",
        "    - The new dataframe without the outliers\n",
        "    '''\n",
        "    shared = remove_outliers(df[df['room_type']=='Shared room'], cols=['price', 'maximum_nights', 'minimum_nights'], q1=0.25, q3=0.75)\n",
        "    priv = remove_outliers(df[df['room_type']=='Private room'], cols=['price', 'maximum_nights', 'minimum_nights'], q1=0.25, q3=0.75)\n",
        "    hot = remove_outliers(df[df['room_type']=='Hotel room'],cols=['price', 'maximum_nights', 'minimum_nights'],q1=0.25, q3=0.75)\n",
        "    home = remove_outliers(df[df['room_type']=='Entire home/apt'],cols=['price', 'maximum_nights', 'minimum_nights'],q1=0.25, q3=0.75)\n",
        "    w_removed_out = pd.concat([shared,priv,hot,home], axis=0)\n",
        "    \n",
        "    return w_removed_out"
      ],
      "metadata": {
        "id": "tfMBSs51XbDN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_amenities(df):\n",
        "    '''\n",
        "    Function that handles the 'amenities' feature. Checks if a list of amenities contains specific strings and if yes it puts a 1 in a new column\n",
        "\n",
        "    Input:\n",
        "    - The dataframe to be processed, needs to have a column named 'amenities'\n",
        "\n",
        "    Output:\n",
        "    A new dataframe with 26 new columns with boolean values for each type of amenity identified\n",
        "    '''\n",
        "    df.loc[df['amenities'].str.contains('kitchen', case=False), 'kitchen'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Air conditioning|Central air conditioning', case=False), 'air_conditioning'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Amazon Echo|Apple TV|Game console|Netflix|Projector and screen|Smart TV', case=False), 'high_end_electronics'] = 1\n",
        "    df.loc[df['amenities'].str.contains('BBQ grill|Fire pit|Propane barbeque', case=False), 'bbq'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Balcony|Patio'), 'balcony'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Beach view|Beachfront|Lake access|Mountain view|Ski-in/Ski-out|Waterfront', case=False), 'nature_and_views'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Bed linens'), 'bed_linen'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Breakfast'), 'breakfast'] = 1\n",
        "    df.loc[df['amenities'].str.contains('TV', case=False), 'tv'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Coffee maker|Espresso machine', case=False), 'coffee_machine'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Cooking basics', case=False), 'cooking_basics'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Elevator', case=False), 'elevator'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Exercise equipment|Gym|gym', case=False), 'gym'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Family/kid friendly|Children|children', case=False), 'child_friendly'] = 1\n",
        "    df.loc[df['amenities'].str.contains('parking', case=False), 'parking'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Garden|Outdoor|Sun loungers|Terrace', case=False), 'outdoor_space'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Host greets you', case=False), 'host_greeting'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Hot tub|Jetted tub|hot tub|Sauna|Pool|pool', case=False), 'hot_tub_sauna_or_pool'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Internet|Pocket wifi|Wifi', case=False), 'internet'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Long term stays allowed', case=False), 'long_term_stays'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Pets|pet|Cat(s)|Dog(s)', case=False), 'pets_allowed'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Private entrance', case=False), 'private_entrance'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Safe|Security system', case=False), 'secure'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Self check-in', case=False), 'self_check_in'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Smoking allowed', case=False), 'smoking_allowed'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Step-free access|Wheelchair|Accessible', case=False), 'accessible'] = 1\n",
        "    df.loc[df['amenities'].str.contains('Suitable for events', case=False), 'event_suitable'] = 1   \n",
        "    \n",
        "    cols_to_replace_nulls = df.columns\n",
        "    df[cols_to_replace_nulls] = df[cols_to_replace_nulls].fillna(0)\n",
        "    df.drop(columns=['amenities'], axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "VEj8gjznXnmT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "def preprocess(df):\n",
        "    '''\n",
        "    Function that combines all the preprocessing steps. It makes the price float, removes outliers based on room types, \n",
        "    handles amenities, fills the missing values, encodes some features and creates the new features\n",
        "\n",
        "    Input:\n",
        "    - The dataframe to be preprocessed\n",
        "\n",
        "    Output:\n",
        "    - The preprocessed dataframe\n",
        "    '''\n",
        "    df['price']= df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
        "    df = remove_outliers_per_room_type(df)\n",
        "    amenities = handle_amenities(df[['amenities']])\n",
        "    df = pd.concat([df,amenities], axis=1)\n",
        "    neigh_mappings = get_neigh_groupings(df)\n",
        "    df = missing_values_n_encoding(df,neigh_mappings)\n",
        "    return df"
      ],
      "metadata": {
        "id": "uoi_dHbyXno7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(data_path + '/listings.csv')\n",
        "data = data.drop(columns=['listing_url', 'scrape_id', 'last_scraped', 'name','description', 'picture_url', 'host_url', 'host_name', \n",
        "                         'host_location','host_thumbnail_url','host_picture_url','host_neighbourhood', 'neighbourhood', 'host_total_listings_count',\n",
        "                         'calendar_updated','bathrooms', 'first_review','last_review', 'calendar_last_scraped',\n",
        "                         'minimum_minimum_nights','maximum_minimum_nights','minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm',\n",
        "                         'maximum_nights_avg_ntm','calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms',\n",
        "                         'calculated_host_listings_count_shared_rooms','host_acceptance_rate', 'neighbourhood_group_cleansed',\n",
        "                         'availability_60','number_of_reviews_ltm','number_of_reviews_l30d', \n",
        "                         'host_listings_count','host_since', 'host_id', 'id','availability_30', 'availability_365', 'reviews_per_month'])\n",
        "data_proc = preprocess(data)\n",
        "data_proc = data_proc.drop(columns=['neighborhood_overview', 'bedrooms', 'beds'])"
      ],
      "metadata": {
        "id": "jDVIGfytXbF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sNBLzP8x4Xp",
        "outputId": "f3cc49d7-7286-4355-bc63-28331f973284"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    8000.000000\n",
              "mean       57.690875\n",
              "std        30.175787\n",
              "min         9.000000\n",
              "25%        36.000000\n",
              "50%        50.000000\n",
              "75%        71.000000\n",
              "max       275.000000\n",
              "Name: price, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "data_proc['price'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-3_Pqe-oKcD"
      },
      "source": [
        "## Mean Price per Neighbourhood - BarChart\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "bqRhcVu7nUZ4"
      },
      "outputs": [],
      "source": [
        "groups_neigh = data_proc.groupby('neighbourhood_cleansed').agg(np.mean)['price']\n",
        "groups_neigh = groups_neigh.sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "VR48AazO2s8A"
      },
      "outputs": [],
      "source": [
        "groups_neigh_1 = groups_neigh[:6]\n",
        "groups_neigh_2 = groups_neigh[6:12]\n",
        "groups_neigh_3 = groups_neigh[12:18]\n",
        "groups_neigh_4 = groups_neigh[18:24]\n",
        "groups_neigh_5 = groups_neigh[24:30]\n",
        "groups_neigh_6 = groups_neigh[30:37]\n",
        "groups_neigh_7 = groups_neigh[37:44]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "3EbvIsjd7rhV"
      },
      "outputs": [],
      "source": [
        "d1 = dict.fromkeys(groups_neigh_1.index, '1')\n",
        "d2 = dict.fromkeys(groups_neigh_2.index, '2')\n",
        "d3 = dict.fromkeys(groups_neigh_3.index, '3')\n",
        "d4 = dict.fromkeys(groups_neigh_4.index, '4')\n",
        "d5 = dict.fromkeys(groups_neigh_5.index, '5')\n",
        "d6 = dict.fromkeys(groups_neigh_6.index, '6')\n",
        "d7 = dict.fromkeys(groups_neigh_7.index, '7')\n",
        "d = {**d1, **d2, **d3, **d4, **d5, **d6, **d7}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "-oXAut9g97xK"
      },
      "outputs": [],
      "source": [
        "data_proc['neigh_group'] = data_proc['neighbourhood_cleansed'].map(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Chdwz-WL972I"
      },
      "outputs": [],
      "source": [
        "groups_neigh_group = data_proc.groupby('neigh_group').agg(np.mean)['price']\n",
        "groups_neigh_group = groups_neigh_group.sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "WdQtqQAkZMqI"
      },
      "outputs": [],
      "source": [
        "d_barChart_all_neigh = {\n",
        "   'price': groups_neigh.values.round(0),\n",
        "   'neighbourhood': groups_neigh.index\n",
        "}\n",
        "barChart_all_neigh = [dict(j) for j in zip( * [\n",
        "   [(a, i) for i in b]\n",
        "   for a, b in d_barChart_all_neigh.items()\n",
        "])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "YQq_G63leXVx"
      },
      "outputs": [],
      "source": [
        "d_treeMap_all_neigh = {\n",
        "   'neighbourhood': groups_neigh.index,\n",
        "    'price': groups_neigh.values.round(2)\n",
        "}\n",
        "treeMap_all_neigh = [dict(j) for j in zip( * [\n",
        "   [(a, i) for i in b]\n",
        "   for a, b in d_treeMap_all_neigh.items()\n",
        "])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "k29yfHftbyJ6"
      },
      "outputs": [],
      "source": [
        "d_barChart_neigh_groups = {\n",
        "   'price': groups_neigh_group.values.round(0),\n",
        "   'group':  'Neighbourhood group ' + groups_neigh_group.index\n",
        "}\n",
        "barChart_neigh_groups = [dict(j) for j in zip( * [\n",
        "   [(a, i) for i in b]\n",
        "   for a, b in d_barChart_neigh_groups.items()\n",
        "])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "pWs1f3u4egpI"
      },
      "outputs": [],
      "source": [
        "d_treeMap_neigh_groups = {\n",
        "    'name':  'Group ' + groups_neigh_group.index,\n",
        "   'price': groups_neigh_group.values.round(0) \n",
        "}\n",
        "treeMap_neigh_groups = [dict(j) for j in zip( * [\n",
        "   [(a, i) for i in b]\n",
        "   for a, b in d_treeMap_neigh_groups.items()\n",
        "])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk1OU9cUe60A"
      },
      "source": [
        "## Mean price of Airbnbs accommodating different number of guests - BarChart\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "9XS4BCAqfYqs"
      },
      "outputs": [],
      "source": [
        "groups_accom = data_proc.groupby('accommodates').agg(np.mean)['price']\n",
        "groups_accom = groups_accom.sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "inNRPizLfYtC"
      },
      "outputs": [],
      "source": [
        "d_barChart_accom = {\n",
        "   'accommodates': groups_accom.index,\n",
        "   'price': groups_accom.values.round(0)\n",
        "}\n",
        "barChart_acom = [dict(j) for j in zip( * [\n",
        "   [(a, i) for i in b]\n",
        "   for a, b in d_barChart_accom.items()\n",
        "])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl-jI2SJgUkL"
      },
      "source": [
        "## Prices - lineChart, AreaChart\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "aKtrwYhSgouK"
      },
      "outputs": [],
      "source": [
        "groups_prices = data_proc['price'].value_counts()\n",
        "groups_prices = groups_prices.sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "VRFmN3ziv_lE"
      },
      "outputs": [],
      "source": [
        "d_barChart_prices = {\n",
        "   'price': groups_prices.index,\n",
        "   'num': groups_prices.values\n",
        "}\n",
        "barChart_prices = [dict(j) for j in zip( * [\n",
        "   [(a, i) for i in b]\n",
        "   for a, b in d_barChart_prices.items()\n",
        "])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf08i7-zgpGf"
      },
      "source": [
        "## Room type, Price - Pie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "u5hONenvg4aZ"
      },
      "outputs": [],
      "source": [
        "groups_room_type = data_proc.groupby('room_type').agg(np.mean)['price'].round(2)\n",
        "groups_room_type = groups_room_type.sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "DORWHacSg4c3"
      },
      "outputs": [],
      "source": [
        "d_pieChart_room_type = {\n",
        "   'type': groups_room_type.index,\n",
        "   'price': groups_room_type.values\n",
        "}\n",
        "\n",
        "pieChart_room_type = [dict(j) for j in zip( * [\n",
        "   [(a, i) for i in b]\n",
        "   for a, b in d_pieChart_room_type.items()\n",
        "])]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "room_type_count = data_proc['room_type'].value_counts()"
      ],
      "metadata": {
        "id": "Z8aUIZfzjmrl"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_pieChart_room_type_count = {\n",
        "   'type': room_type_count.index,\n",
        "   'count': room_type_count.values\n",
        "}\n",
        "pieChart_room_type_count = [dict(j) for j in zip( * [\n",
        "   [(a, i) for i in b]\n",
        "   for a, b in d_pieChart_room_type_count.items()\n",
        "])]\n",
        "pieChart_room_type_count = [{'type': 'Shared room', 'count': 52},{'type': 'Entire home/apt', 'count': 7105},\n",
        " {'type': 'Private room', 'count': 728},{'type': 'Hotel room', 'count': 115}]"
      ],
      "metadata": {
        "id": "JOS2qmZGjmt5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export stats"
      ],
      "metadata": {
        "id": "m2KW--XzjiJZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "G1hFxiL0g4pD"
      },
      "outputs": [],
      "source": [
        "jsonDict = {\n",
        "  'barChart_all_neigh': barChart_all_neigh,\n",
        "  'barChart_groups': barChart_neigh_groups,\n",
        "  'treeMap_all_neigh': treeMap_all_neigh,\n",
        "  'treeMap_groups': treeMap_neigh_groups,\n",
        "  'barChart_acom': barChart_acom,\n",
        "  'barChart_prices': barChart_prices,\n",
        "  'pieChart_room_type': pieChart_room_type,\n",
        "  'pieChart_room_type_count': pieChart_room_type_count\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "6wJd_gnr_qse"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/project/json_test.json', 'w', encoding='utf-8') as file:\n",
        "    json.dump(jsonDict, file, ensure_ascii=False, cls=NumpyEncoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Host info"
      ],
      "metadata": {
        "id": "BjGqMbaXb54q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data_path + '/listings.csv')"
      ],
      "metadata": {
        "id": "xz15RIghb9V8"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hosts = df[['host_id',  'host_about', 'host_response_time', 'host_response_rate',\n",
        "        'host_is_superhost', 'host_verifications', \n",
        "        'calculated_host_listings_count','host_identity_verified','host_has_profile_pic']]"
      ],
      "metadata": {
        "id": "3ETQYR1-o4WN"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hosts = df_hosts.drop_duplicates()"
      ],
      "metadata": {
        "id": "r1LQ0SRgpaQj"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hosts.to_csv(data_path + '/host_info.csv')  "
      ],
      "metadata": {
        "id": "hJcp8fg8ifJm"
      },
      "execution_count": 72,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}